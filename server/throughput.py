#!/usr/bin/env python

# Generates a graphic from the dataset generated in Redis Instant Recovery (Redis IR).
# The graphic shows the database transaction throughput (number of commands executed) over time (seconds).
# The graphic is generated by a dataset is a CSV file containing the fields key, command,
# startTime, finishTime and type.
# Each line of the CSV file represents a command execution on database.

# The three first CSV data lines are not executed commands, they are the time (in seconds) of database startup, recovery,
# and benchmark execution. When thetime is not obtained, the value is -1.
# Belows the fields used:
# key commands startTime finishTime type
# "Database startup" <obtained time> 0
# "Shutdown" <obtained time> 0
# "Recovery" <obtained time> <obtained time> 0
# "Benchmark" <obtained time> <obtained time> 0

# Checkpoint process information is stored before the commands executed as bellows:
# key command startTime finishTime type
# "Checkpoint" <idCheckpoint> <obtained time> <obtained time> 0
# "Checkpoint End" <idCheckpoint> <obtained time> 0

# The remaind CSV data lines are really executed commands.
# key command startTime finishTime type
# <command key> <command performed> <obtained time> <obtained time> <command type>

import csv

# Constants for the CSV columns
KEY = 0
COMMAND = 1
START_TIME = 2
FINISH_TIME = 3
TYPE = 4

# Constants for the special events
DATABASE_STARTUP = "Database startup"
SHUTDOWN = "Shutdown"
RECOVERY = "Recovery"
BENCHMARK = "Benchmark"
CHECKPOINT = "Checkpoint"
CHECKPOINT_END = "Checkpoint End"

def read_data(path):
    """Reads and processes the data from the CSV file."""
    with open(path) as file:
            # Reads the CSV file as a list of rows
        data = list(csv.reader(file))

        # Counts the lines of the dataset
        total = len(data)

        # Gets the database start up time
        database_startup_time = int(data[1][START_TIME])

        # Removes header and database start up information
        data.pop(0)
        data.pop(0)

        '''
        Creates a list of items from column 'endTime' (in microseconds) of the dataset 
        and converts all items to seconds. Additionally, these items are converted to 
        relative time to the database start up time, i.e, the database start up time 
        will be the zero time. 
        '''
        database_startup = 0
        database_recovery = 0
        end_time_list = [] # Stores the endTime of a performed command.
        other_elements = [] 
        for row in data:
            if row[TYPE] != "0\n": # Stores the endTime of a performed command.
                if row[FINISH_TIME].isnumeric():# prevents to a possible corrupted data
                    time = int((int(row[FINISH_TIME]) - database_startup_time)/1000000)
                    end_time_list.append(time) #finishTime
            else: # Stores the database startup time, system restart time, recovery time, or bechmark finish time.
                element = []
                if row[KEY] == DATABASE_STARTUP:
                    element.append("System restart")
                    time = float((int(row[START_TIME]) - database_startup_time)/1000000)
                    element.append(time)
                    database_startup = time
                elif row[KEY] == SHUTDOWN:
                    element.append("System failure")
                    time = float((int(row[START_TIME]) - database_startup_time)/1000000)
                    element.append(time)
                elif row[KEY] == RECOVERY:
                    start_time = float((int(row[START_TIME]) - database_startup_time)/1000000)
                    if start_time > 0:
                        element.append("Recovery")
                        element.append(start_time)
                        finish_time = float((int(row[FINISH_TIME]) - database_startup_time)/1000000)
                        element.append(finish_time)
                        database_recovery = finish_time
                elif row[KEY] == BENCHMARK:
                    element.append("Benchmark")
                    start_time = float((int(row[START_TIME]) - database_startup_time)/1000000)
                    element.append(start_time)
                    finish_time = float((int(row[FINISH_TIME]) - database_startup_time)/1000000)
                    element.append(finish_time)
                elif row[KEY] == CHECKPOINT:
                    element.append("Checkpoint") # Checkpoint
                    element.append(row[COMMAND]) # checkpoint ID
                    start_time = (int(row[START_TIME])-database_startup_time)/1000000 # start time
                    element.append(start_time)
                    finish_time = (int(row[FINISH_TIME])-database_startup_time)/1000000 # end time
                    element.append(finish_time)
                elif row[KEY] == CHECKPOINT_END:
                    element.append("Checkpoint End") # End of the checkpoint
                    element.append(row[COMMAND]) # checkpoint ID
                    finish_time = (int(row[FINISH_TIME])-database_startup_time)/1000000 # end time
                    element.append(finish_time)
                if element:
                    other_elements.append(element)

        end_time_list.sort()

    return total, end_time_list, other_elements, database_startup, database_recovery

def calculate_throughput(end_time_list, other_elements, database_startup, database_recovery):
    """Calculates the throughput averages for different periods."""
    x = list(range(0, max(end_time_list))) # List from zero to maximum end of time 
    y = [0] * max(end_time_list) # List o zeros

    # Stores in y the number items in x that are in endTimeList
    j = 0
    i = 0
    max_list = len(x)
    while i < max_list:
        if x[i] == end_time_list[j]:
            y[i] += 1
            j += 1
        else:
            i += 1

    sum_throughput_before_database_startup = 0
    sum_throughput_after_database_recovery = 0
    sum_throughput_during_database_recovery = 0
    total1 = 0
    total2 = 0
    total3 = 0
    for i in range(len(y)):
        if x[i] < database_startup:
            sum_throughput_before_database_startup = sum_throughput_before_database_startup + y[i]
            total1 = total1 + 1
        elif x[i] > database_recovery:
            sum_throughput_after_database_recovery = sum_throughput_after_database_recovery + y[i]
            total2 = total2 + 1
        elif x[i] > database_startup:
            sum_throughput_during_database_recovery = sum_throughput_during_database_recovery + y[i]
            total3 = total3 + 1
    if total1 != 0:
        print(f"Average throughput before database startup = {sum_throughput_before_database_startup/total1}")
    if total2 != 0:
        print(f"Average throughput after database recovery = {sum_throughput_after_database_recovery/total2}")
    if total3 != 0:
        print(f"Average throughput during database recovery = {sum_throughput_during_database_recovery/total3}")
    print(f"Average throughput = {(sum_throughput_before_database_startup + sum_throughput_after_database_recovery + sum_throughput_during_database_recovery)/(total1 + total2 + total3)}")

    return x, y, other_elements

def generate_graphic(x, y, other_elements):
    """Generates the graphic from the data."""
    # TODO: implement the graphic generation logic
    pass

def main():
    """Main function."""
    print("Choose the dataset file!")
    filename = "./ir.csv"
    print(f"Chosen file: {filename}")

    print("\nReading the dataset ... Wait!\n")
    x_data = []
    y_data = []
    other_elements = []

    total, end_time_list, other_elements, database_startup, database_recovery = read_data(filename)
    x_data, y_data, other_elements = calculate_throughput(end_time_list, other_elements, database_startup, database_recovery)
    
    print(x_data, y_data, other_elements)

    generate_graphic(x_data, y_data, other_elements)

if __name__ == "__main__":
    main()
